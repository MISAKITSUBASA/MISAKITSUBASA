# ðŸ‘‹ Hi, I'm Qian Tang (å”éªž)

ðŸ§  M.S. in Computer Science @ NYU Courant  
ðŸŽ“ Previously @ University of Toronto â€” ECE (MEng) & CS/Math/Stats (BSc)  
ðŸ”¬ LLM Infrastructure Â· ML Systems Â· Model Training & Architecture Â· Applied Reasoning

---

## ðŸŒ Who I Am

Iâ€™m a machine learning engineer and researcher focused on making foundation models **faster, smarter, and more reliable in the real world**.  
My work lives at the intersection of **language, reasoning, architecture design, and ML infra** â€” from model training to production deployment.

> I build systems that help large models think clearly, serve responsibly, and improve over time.

---

## ðŸ§  What I Work On

### âš™ï¸ LLM Infrastructure & ML Systems  
I design and scale latency-critical pipelines for:
- Retrieval-augmented generation (RAG)  
- Semantic search with FAISS and caching with Redis  
- Prompt orchestration and confidence-based fallback  
- Logging, routing, and escalation triggers

I care about systems that **degrade gracefully, respond instantly, and adapt safely**.

---

### ðŸ§¬ Model Training & Architecture  
I donâ€™t just deploy models â€” I also train and experiment with them.

I explore:
- **Contrastive learning** (e.g., SoftCLIP) for robust representation under ambiguity  
- **ViT + transformer variants** for structured signal understanding and interpretability  
- **Multi-exit and token-pruned transformers** for latency-efficient inference  
- **LLM alignment** through prompt tuning, confidence scoring, and supervised fine-tuning

Whether itâ€™s building token-efficient transformers or embedding feedback signals into the learning loop, I care deeply about **how models reason â€” not just what they output**.

---

### ðŸ” Feedback-Aware Intelligence  
I design systems where models improve over time through:
- Confidence-based routing and auto-escalation  
- Logging agent edits as implicit supervision  
- Closed-loop ML workflows that learn from real outcomes  
- Metric pipelines grounded in business impact (not just F1)

---

## ðŸš€ What I'm Building Toward

- ðŸ§  Smarter architectures: models that donâ€™t just complete prompts, but **reason, defer, and ask for help**  
- âš™ï¸ Robust systems: LLM APIs that donâ€™t fail silently, and infra that explains itself under pressure  
- ðŸ”„ Adaptive learning loops: pipelines where **production traffic becomes the training signal**

---

## ðŸ“« Reach Me

- âœ‰ï¸ [qian.tang.1999@outlook.com](mailto:qian.tang.1999@outlook.com) (Work)  
- ðŸŽ“ [qt2118@nyu.edu](mailto:qt2118@nyu.edu) (Academic)

---

> *I train models. I deploy them. And I build the systems that help them improve.*
