# 👋 Hi, I'm Qian Tang (唐骞)

🧠 M.S. in Computer Science @ NYU Courant  
🎓 Previously @ University of Toronto — ECE (MEng) & CS/Math/Stats (BSc)  
🔬 LLM Infrastructure · ML Systems · Model Training & Architecture · Applied Reasoning

---

## 🌐 Who I Am

I’m a machine learning engineer and researcher focused on making foundation models **faster, smarter, and more reliable in the real world**.  
My work lives at the intersection of **language, reasoning, architecture design, and ML infra** — from model training to production deployment.

> I build systems that help large models think clearly, serve responsibly, and improve over time.

---

## 🧠 What I Work On

### ⚙️ LLM Infrastructure & ML Systems  
I design and scale latency-critical pipelines for:
- Retrieval-augmented generation (RAG)  
- Semantic search with FAISS and caching with Redis  
- Prompt orchestration and confidence-based fallback  
- Logging, routing, and escalation triggers

I care about systems that **degrade gracefully, respond instantly, and adapt safely**.

---

### 🧬 Model Training & Architecture  
I don’t just deploy models — I also train and experiment with them.

I explore:
- **Contrastive learning** (e.g., SoftCLIP) for robust representation under ambiguity  
- **ViT + transformer variants** for structured signal understanding and interpretability  
- **Multi-exit and token-pruned transformers** for latency-efficient inference  
- **LLM alignment** through prompt tuning, confidence scoring, and supervised fine-tuning

Whether it’s building token-efficient transformers or embedding feedback signals into the learning loop, I care deeply about **how models reason — not just what they output**.

---

### 🔁 Feedback-Aware Intelligence  
I design systems where models improve over time through:
- Confidence-based routing and auto-escalation  
- Logging agent edits as implicit supervision  
- Closed-loop ML workflows that learn from real outcomes  
- Metric pipelines grounded in business impact (not just F1)

---

## 🚀 What I'm Building Toward

- 🧠 Smarter architectures: models that don’t just complete prompts, but **reason, defer, and ask for help**  
- ⚙️ Robust systems: LLM APIs that don’t fail silently, and infra that explains itself under pressure  
- 🔄 Adaptive learning loops: pipelines where **production traffic becomes the training signal**

---

## 📫 Reach Me

- ✉️ [qian.tang.1999@outlook.com](mailto:qian.tang.1999@outlook.com) (Work)  
- 🎓 [qt2118@nyu.edu](mailto:qt2118@nyu.edu) (Academic)

---

> *I train models. I deploy them. And I build the systems that help them improve.*
