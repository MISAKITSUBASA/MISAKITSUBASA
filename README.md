# 👋 Hi, I'm Qian Tang (唐骞)

🧠 CS Master's @ NYU Courant  
🎓 Previously @ University of Toronto — ECE (MEng) & CS/Math/Stats (BSc)  
🧩 LLM Infrastructure · ML Systems · Applied Model Architecture · Language x Reasoning

---

## 🌐 Who I Am

I'm an engineer–scientist hybrid working at the intersection of **foundation model research and real-world deployment**.  
I care about building ML systems that aren’t just accurate — but **aware, adaptive, and architecturally honest**.

In short:  
> I build intelligent systems that help large models think clearly, serve responsibly, and evolve safely — under real-world constraints.

---

## 🧠 What I Work On

My focus spans three deeply interconnected tracks:

### 🔧 ML Infrastructure  
How do we serve, route, and observe LLMs at production scale?  
I design low-latency, fault-tolerant pipelines for semantic retrieval, prompt orchestration, fallback reasoning, and caching.  
My systems aim to make large models **feel instant, grounded, and controllable** — without compromising flexibility.

### 🧬 Model Architecture  
How do we make LLMs smarter, leaner, and more human-aligned?  
I explore hybrid architectures:  
- **Soft contrastive learning** to improve alignment under ambiguity  
- **ViT and cross-modal models** for structure-aware learning  
- **Multi-exit transformers** and **token-pruned inference paths** to reduce latency while preserving reasoning depth  
I care about **making models more efficient not just by compression, but by structure**.

### 🔁 Feedback-Driven ML  
How do we help models learn post-deployment — from users, agents, and failure cases?  
I design schema and pipelines for **real-time feedback**, **confidence-based escalation**, and **continuous evaluation** tied to real outcomes.  
Think: model predictions as first drafts, and the world as its annotator.

---

## 🚧 What I'm Working Toward

I don’t just ship models — I’m building toward:

- 🔎 **Interpretable, multi-stage language systems** that can reflect, reroute, or defer
- ⚙️ **Robust AI infrastructure** where caching, degradation, and feedback are first-class citizens
- 🧠 **Efficient model architectures** that balance latency, alignment, and reasoning
- 🔄 **Closed-loop AI workflows** where human edits and business signals improve the next prediction

I want to engineer systems where models don’t just “perform”, but **adapt and justify**.

---

## 📫 Get in Touch

- ✉️ [qian.tang.1999@outlook.com](mailto:qian.tang.1999@outlook.com) (Work)  
- 🎓 [qt2118@nyu.edu](mailto:qt2118@nyu.edu) (Academic)

---

> *I don’t just run models. I build the systems around them that make them useful — and the feedback loops that make them better.*
